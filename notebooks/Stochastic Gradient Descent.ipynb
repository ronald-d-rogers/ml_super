{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.getcwd().split('/')[-1] == 'notebooks':\n",
        "    os.chdir(os.path.dirname(os.path.abspath('')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "playing = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Playing the Animation\n",
        "\n",
        "### Chapters\n",
        "* guassian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if playing:\n",
        "    chapters = [\"fail-gaussian\"]\n",
        "    show_model = True\n",
        "    show_gradients = False\n",
        "    show_params = True\n",
        "    show_network = False\n",
        "    model_node = \"output_1\"\n",
        "    theme = \"dark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from animation import animate\n",
        "from animations import sgd\n",
        "\n",
        "theme_args = dict(\n",
        "    cost_label_yshift=700,\n",
        "    cost_label_xshift=80,\n",
        "    label_yshift=-200,\n",
        "    parameters_line_width=18,\n",
        ")\n",
        "\n",
        "args = dict(\n",
        "    show_bg=True,\n",
        "    show_params=True,\n",
        "    show_gradients=False,\n",
        "    show_network=False,\n",
        "    theme=theme,\n",
        "    model_node=model_node,\n",
        "    theme_args=theme_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'ViewFrameUpdate' object has no attribute 'scene'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m playing:\n\u001b[1;32m      2\u001b[0m     frames \u001b[38;5;241m=\u001b[39m sgd\u001b[38;5;241m.\u001b[39mget_animation(chapters\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43manimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Code/ml_super/animation.py:11\u001b[0m, in \u001b[0;36manimate\u001b[0;34m(frames, framework, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manimate\u001b[39m(\n\u001b[1;32m      6\u001b[0m     frames: \u001b[38;5;28mlist\u001b[39m[AnimationFrame],\n\u001b[1;32m      7\u001b[0m     framework: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m      9\u001b[0m ):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manimate_plotly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown framework: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframework\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Code/ml_super/adapters/plotly.py:194\u001b[0m, in \u001b[0;36manimate\u001b[0;34m(frames, model_node, show_model, show_params, show_gradients, show_tables, show_network, show_bg, show_weight_preds, scrollable, scale, render_path, theme, theme_args)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_network:\n\u001b[1;32m    192\u001b[0m     layout\u001b[38;5;241m.\u001b[39madd_component(NeuralNetworkComponent(animation))\n\u001b[0;32m--> 194\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mlayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# fig = make_subplots(\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m#     rows=layout.row_count,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m#     cols=layout.column_count,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m#     fig.update_yaxes(range=[-2, 0], row=cell[\"row\"], col=cell[\"col\"])\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m#     fig.update_xaxes(range=[-1.5, 1.5], row=cell[\"row\"], col=cell[\"col\"])\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render_path:\n",
            "File \u001b[0;32m~/Code/ml_super/adapters/plotly.py:56\u001b[0m, in \u001b[0;36mPlotlyLayout.create_figure\u001b[0;34m(self, first_frame)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m component\u001b[38;5;241m.\u001b[39mcreate_component(view, first_frame):\n\u001b[0;32m---> 56\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mupdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscene\u001b[49m:\n\u001b[1;32m     57\u001b[0m             fig\u001b[38;5;241m.\u001b[39mlayout[get_scene_key(scene_count)]\u001b[38;5;241m.\u001b[39mupdate(update\u001b[38;5;241m.\u001b[39mscene)\n\u001b[1;32m     58\u001b[0m             scene_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ViewFrameUpdate' object has no attribute 'scene'"
          ]
        }
      ],
      "source": [
        "if playing:\n",
        "    frames = sgd.get_animation(chapters='gaussian')\n",
        "    animate(frames, **args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rendering the Animation\n",
        "\n",
        "Due to issues with Plotly's artifacts during rendering we have to render each component individually and merge them into one video using ffmpeg\n",
        "\n",
        "### Required Software\n",
        "\n",
        "#### ImageMagick\n",
        "\n",
        "`brew install imagemagick`\n",
        "\n",
        "#### ffmpeg\n",
        "\n",
        "`brew install ffmpeg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from animation import animate\n",
        "from animations import neural_networks\n",
        "\n",
        "render_path = \"renders/neural_networks\"\n",
        "frame_rate = 14\n",
        "\n",
        "if not playing:\n",
        "    chapters = [\"gaussian\"]\n",
        "    nodes = [\"output_1\", \"hidden_1\", \"hidden_2\", \"hidden_3\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_pngs_command(input_files, output_file, background=\"white\"):\n",
        "    return f\"convert {' '.join(reversed(input_files))} -background {background} -layers Flatten {output_file}\"\n",
        "\n",
        "def create_video_command(input_path, output_file, frame_rate):\n",
        "    files = len([name for name in os.listdir(input_path) if name.endswith('.png')])\n",
        "    file_pattern = '%02d' if files < 100 else '%03d'\n",
        "    return f\"ffmpeg -y -r {frame_rate} -i {input_path}/{file_pattern}.png -vcodec libx264 -pix_fmt yuv420p {output_file}.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_chapters = [\"logistic\", \"xor\", \"neural\", \"fit\", \"weights\"]\n",
        "output_nodes = [\"output_1\"]\n",
        "output_parameters = [\"model\"]\n",
        "\n",
        "if not playing:\n",
        "    for node in output_nodes:\n",
        "        if nodes and node not in nodes:\n",
        "            continue\n",
        "\n",
        "        for chapter in output_chapters:\n",
        "            if chapters and chapter not in chapters:\n",
        "                continue\n",
        "\n",
        "            print(f'Rendering {node} for \"{chapter}\"')\n",
        "\n",
        "            frames = neural_networks.get_animation(chapters=[chapter])\n",
        "\n",
        "            path = f\"{render_path}/{chapter}/output_1/model\"\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                os.system(f\"rm -rf {path}\")\n",
        "\n",
        "            animate(\n",
        "                frames,\n",
        "                show_model=True,\n",
        "                show_params=True,\n",
        "                parameter_line_width=18,\n",
        "                label_yshift=-30,\n",
        "                show_bg=False,\n",
        "                render_path=path,\n",
        "            )\n",
        "\n",
        "            print(f'Creating video for \"{node}\"')\n",
        "\n",
        "            folder = f\"{render_path}/{chapter}/{node}\"\n",
        "            folders = [f\"{folder}/{parameter}\" for parameter in output_parameters]\n",
        "\n",
        "            for file in tqdm.tqdm(os.listdir(folders[0])):\n",
        "                if file.endswith(\".png\"):\n",
        "                    files = [os.path.join(folder, file) for folder in folders]\n",
        "                    os.system(merge_pngs_command(files, f\"{folder}/{file}\", \"green\"))\n",
        "\n",
        "            os.system(create_video_command(folder, f\"{render_path}/{chapter}/{node}\", frame_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_chapters = [\"gaussian\"]\n",
        "output_nodes = [\"output_1\"]\n",
        "output_parameters = [\"model\"]\n",
        "\n",
        "if not playing:\n",
        "    for node in output_nodes:\n",
        "        if nodes and  node not in nodes:\n",
        "            continue\n",
        "\n",
        "        for chapter in output_chapters:\n",
        "            if chapters and chapter not in chapters:\n",
        "                continue\n",
        "\n",
        "            print(f'Rendering {node} for \"{chapter}\"')\n",
        "\n",
        "            frames = neural_networks.get_animation(chapters=[chapter])\n",
        "\n",
        "            path = f\"{render_path}/{chapter}/{node}/model\"\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                os.system(f\"rm -rf {path}\")\n",
        "\n",
        "            animate(\n",
        "                frames,\n",
        "                show_model=True,\n",
        "                show_params=False,\n",
        "                parameter_line_width=18,\n",
        "                label_yshift=-100,\n",
        "                show_bg=False,\n",
        "                render_path=path,\n",
        "            )\n",
        "\n",
        "            print(f'Creating video for \"{node}\"')\n",
        "\n",
        "            folder = f\"{render_path}/{chapter}/{node}\"\n",
        "            folders = [f\"{folder}/{parameter}\" for parameter in output_parameters]\n",
        "\n",
        "            for file in tqdm.tqdm(os.listdir(folders[0])):\n",
        "                if file.endswith(\".png\"):\n",
        "                    files = [os.path.join(folder, file) for folder in folders]\n",
        "                    os.system(merge_pngs_command(files, f\"{folder}/{file}\", \"green\"))\n",
        "\n",
        "            os.system(create_video_command(folder, f\"{render_path}/{chapter}/{node}\", frame_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden_chapters = [\"neural\", \"fit\"]\n",
        "hidden_nodes = [\"hidden_1\", \"hidden_2\"]\n",
        "hidden_parameters = [\"model\"]\n",
        "\n",
        "if not playing:\n",
        "    for node in hidden_nodes:\n",
        "        if nodes and node not in nodes:\n",
        "            continue\n",
        "\n",
        "        for chapter in hidden_chapters:\n",
        "            if chapters and chapter not in chapters:\n",
        "                continue\n",
        "\n",
        "            print(f'Rendering {node} for \"{chapter}\"')\n",
        "\n",
        "            frames = neural_networks.get_animation(chapters=[chapter])\n",
        "\n",
        "            path = f\"{render_path}/{chapter}/{node}/model\"\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                os.system(f\"rm -rf {path}\")\n",
        "\n",
        "            animate(\n",
        "                frames,\n",
        "                model_node=node,\n",
        "                show_model=True,\n",
        "                show_params=True,\n",
        "                show_label_names=False,\n",
        "                label_precision=2,\n",
        "                label_font_size=110,\n",
        "                label_yshift=60,\n",
        "                show_bg=False,\n",
        "                render_path=path,\n",
        "            )\n",
        "\n",
        "            print(f'Creating video for \"{node}\"')\n",
        "\n",
        "            folder = f\"{render_path}/{chapter}/{node}\"\n",
        "            folders = [f\"{folder}/{parameter}\" for parameter in hidden_parameters]\n",
        "\n",
        "            for file in tqdm.tqdm(os.listdir(folders[0])):\n",
        "                if file.endswith(\".png\"):\n",
        "                    files = [os.path.join(folder, file) for folder in folders]\n",
        "                    os.system(merge_pngs_command(files, f\"{folder}/{file}\", \"green\"))\n",
        "\n",
        "            os.system(create_video_command(folder, f\"{render_path}/{chapter}/{node}\", frame_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gaussian_chapters = [\"gaussian\"]\n",
        "gaussian_nodes = [\"hidden_1\", \"hidden_2\", \"hidden_3\"]\n",
        "gaussian_parameters = [\"model\"]\n",
        "\n",
        "if not playing:\n",
        "    for node in gaussian_nodes:\n",
        "        if nodes and node not in nodes:\n",
        "            continue\n",
        "\n",
        "        for chapter in gaussian_chapters:\n",
        "            if chapters and chapter not in chapters:\n",
        "                continue\n",
        "\n",
        "            print(f'Rendering {node} for \"{chapter}\"')\n",
        "\n",
        "            frames = neural_networks.get_animation(chapters=[chapter])\n",
        "\n",
        "            path = f\"{render_path}/{chapter}/{node}/model\"\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                os.system(f\"rm -rf {path}\")\n",
        "\n",
        "            animate(\n",
        "                frames,\n",
        "                model_node=node,\n",
        "                show_model=True,\n",
        "                show_params=True,\n",
        "                show_label_names=False,\n",
        "                label_precision=2,\n",
        "                label_font_size=110,\n",
        "                label_yshift=60,\n",
        "                show_bg=False,\n",
        "                render_path=path,\n",
        "            )\n",
        "\n",
        "            print(f'Creating video for \"{node}\"')\n",
        "\n",
        "            folder = f\"{render_path}/{chapter}/{node}\"\n",
        "            folders = [f\"{folder}/{parameter}\" for parameter in gaussian_parameters]\n",
        "\n",
        "            for file in tqdm.tqdm(os.listdir(folders[0])):\n",
        "                if file.endswith(\".png\"):\n",
        "                    files = [os.path.join(folder, file) for folder in folders]\n",
        "                    os.system(merge_pngs_command(files, f\"{folder}/{file}\", \"green\"))\n",
        "\n",
        "            os.system(create_video_command(folder, f\"{render_path}/{chapter}/{node}\", frame_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_chapters = [\"logistic\", \"xor\", \"fit\", \"neural\", \"gaussian\"]\n",
        "network_nodes = [\"network\"]\n",
        "\n",
        "if not playing:\n",
        "    for node in network_nodes:\n",
        "        if nodes and node not in nodes:\n",
        "            continue\n",
        "\n",
        "        for chapter in network_chapters:\n",
        "            if chapters and chapter not in chapters:\n",
        "                continue\n",
        "\n",
        "            print(f'Rendering {node} for \"{chapter}\"')\n",
        "\n",
        "            frames = neural_networks.get_animation(chapters=[chapter])\n",
        "\n",
        "            path = f\"{render_path}/{chapter}/{node}/network\"\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                os.system(f\"rm -rf {path}\")\n",
        "\n",
        "            animate(\n",
        "                frames,\n",
        "                show_model=False,\n",
        "                show_params=False,\n",
        "                show_network=True,\n",
        "                render_path=path,\n",
        "            )\n",
        "\n",
        "            print(f'Creating video for \"{node}\"')\n",
        "\n",
        "            output_folder = f\"{render_path}/{chapter}/{node}\"\n",
        "            input_folder = f\"{render_path}/{chapter}/{node}/network\"\n",
        "\n",
        "            for file in tqdm.tqdm(os.listdir(input_folder)):\n",
        "                if file.endswith(\".png\"):\n",
        "                    files = [os.path.join(input_folder, file)]\n",
        "                    os.system(merge_pngs_command(files, f\"{output_folder}/{file}\"))\n",
        "\n",
        "            os.system(create_video_command(output_folder, output_folder, frame_rate))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
